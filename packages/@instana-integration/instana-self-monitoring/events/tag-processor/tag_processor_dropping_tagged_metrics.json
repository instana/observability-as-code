{
  "name": "[SRESLO] tag-processor is dropping tagged metrics [TF]",
  "description": "Tag processor is having trouble keeping up with the number of tagged metrics that are being published from some TUs. ## Consequences As long as this occurs, there may be delays in multi-dimensional metrics in custom dashboards and Analyze Infrastructure for some TUs. ## Remediation Steps to take _until remediation_ - Verify that there are no issues with Kafka. - Consider increasing the number of tag-processor instances to keep up with increased load. - Consider decreasing the filler tagged metric publish count  You can go to an individual tag-processor dropiwizard dashboard to see which TUs are affected (check the `com.instana.tags.processing.TaggedMetricDropper.<tenant-unit>.error_rate` metrics)  To get more context: [ðŸ”µ](https://blue-instanaops.instana.io/#/customDashboards/view;dashboardId=l6yRfqedQn-t_GqhGVHYmg) [ðŸŸ¢](https://green-instanaops.instana.io/#/customDashboards/view;dashboardId=9VDfDX1UQ7yAMuBj14CK7A) [ðŸ”´](https://red-instanaops.instana.io/#/customDashboards/view;dashboardId=jDwGyhY8SAq88FJXvtsqIg) [ðŸŸ ](https://orange-instanaops.instana.io/#/customDashboards/view;dashboardId=YalysPDKRoGpzuagPYtWwg)",
  "query": "entity.jvm.app.name:tag-processor",
  "entityType": "dropwizardApplicationContainer",
  "expirationTime": 600000,
  "rules": [
    {
      "ruleType": "threshold",
      "metricName": "metrics.gauges.com.instana.tags.processing.TaggedMetricDropper.error_rate{tenantUnit=\"all\"}",
      "aggregation": "avg",
      "window": 300000,
      "conditionOperator": ">",
      "conditionValue": 0.01,
      "severity": 5
    }
  ]
}
